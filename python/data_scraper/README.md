# Data Scraper - DisastersCharter.org
## Coleta AutomÃ¡tica de Dados de Enchentes

---

## ğŸ“‹ DESCRIÃ‡ÃƒO

Script Python para coleta automÃ¡tica de dados de enchentes do site oficial **DisastersCharter.org** usando sua API interna. Desenvolvido especificamente para a Global Solution 2025.

---

## ğŸš€ FUNCIONALIDADES

- âœ… **Coleta AutomÃ¡tica**: Busca eventos de enchentes em mÃºltiplas regiÃµes
- âœ… **API Interna**: Utiliza a API real do DisastersCharter.org
- âœ… **Dados Estruturados**: Extrai JSON com metadados completos
- âœ… **MÃºltiplas RegiÃµes**: South America, Africa, Asia, Europe, North America
- âœ… **Rate Limiting**: Respeita limites do servidor (2s entre requests)
- âœ… **DeduplicaÃ§Ã£o**: Remove eventos duplicados automaticamente
- âœ… **Logs Detalhados**: Acompanhamento completo da execuÃ§Ã£o
- âœ… **Tratamento de Erros**: Robusto contra falhas de rede

---

## ğŸ“¦ INSTALAÃ‡ÃƒO

### **PrÃ©-requisitos**
- Python 3.7+
- pip3

### **Setup Ambiente Ãšnico**
```bash
# Setup ambiente Ãºnico
cd python/
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Instalar dependÃªncias
pip install -r data_scraper/requirements.txt
```

---

## ğŸ”§ USO

### **ExecuÃ§Ã£o Simples**
```bash
# Setup ambiente Ãºnico
cd python/
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Executar scraper
python data_scraper/disasters_scraper.py
```

### **Outros Scripts**
```bash
# Enriquecer dados com duraÃ§Ã£o
python data_scraper/enrich_duration.py

# Baixar relatÃ³rios
python data_scraper/download_reports.py

# Baixar imagens
python data_scraper/download_images.py
```

### **Como MÃ³dulo Python**
```python
from disasters_scraper import DisastersCharterScraper

# Criar instÃ¢ncia
scraper = DisastersCharterScraper()

# Coletar dados
flood_data = scraper.get_flood_activations()

print(f"Coletados {len(flood_data)} eventos de enchentes")
```

### **Personalizar RegiÃµes**
```python
# Buscar apenas AmÃ©rica do Sul
data = scraper.get_flood_activations(location="south america")

# Buscar mÃºltiplas regiÃµes especÃ­ficas
regions = ["africa", "asia"]
for region in regions:
    data = scraper.get_flood_activations(location=region)
```

### **Enriquecimento Completo com DuraÃ§Ã£o**
```bash
# Executar enriquecimento completo de TODOS os eventos
python enrich_duration.py
```

**Resultados do Enriquecimento:**
- âœ… **27 eventos processados** - todos os eventos coletados
- âœ… **InformaÃ§Ãµes de impacto extraÃ­das** - mortes, deslocados, etc.
- âœ… **DuraÃ§Ã£o identificada** - quando disponÃ­vel (ex: MÃ©xico 3 dias)
- âœ… **Estrutura completa** - campo `duration` em todos os eventos

**Arquivo gerado:**
```
../../data/processed/flood_events_enriched_complete.json
```

### **Download de RelatÃ³rios TÃ©cnicos**
```bash
# Baixar 5 relatÃ³rios tÃ©cnicos oficiais
python download_reports.py
```

**Resultados do Download:**
- âœ… **5 relatÃ³rios baixados** - meta atingida
- âœ… **RelatÃ³rios anuais** - Charter Annual Report 2022 e 2023
- âœ… **Documentos tÃ©cnicos** - Brand Guidelines
- âœ… **Newsletters** - Issues 29 e 30
- âœ… **Metadados salvos** - reports_metadata.json

**Arquivos gerados:**
```
../../data/reports/
â”œâ”€â”€ report_01_Charter_Annual_Report_23.pdf
â”œâ”€â”€ report_02_Charter_Annual_Report_22.pdf
â”œâ”€â”€ report_03_The_International_Charter_Brand_Guidelines.pdf
â”œâ”€â”€ report_04_Charter_Newsletter_Issue_30.pdf
â”œâ”€â”€ report_05_Charter_Newsletter_Issue_29.pdf
â””â”€â”€ reports_metadata.json
```

### **Download de Imagens de SatÃ©lite**
```bash
# Baixar todas as imagens de satÃ©lite disponÃ­veis (quickviews de enchentes)
python download_images.py
```

**Resultados do Download:**
- âœ… **12 imagens baixadas** - superou expectativas (6 quickviews Ã— 2 imagens cada)
- âœ… **Imagens prÃ© e pÃ³s-desastre** - comparaÃ§Ã£o temporal completa
- âœ… **Cobertura global** - Espanha, Sri Lanka, Brasil, EscÃ³cia, RÃºssia
- âœ… **SatÃ©lites diversos** - Sentinel-1, Amazonia-1, CBERS-4, RCM, SAOCOM
- âœ… **Metadados completos** - paÃ­s, satÃ©lite, dimensÃµes, copyright

**Arquivos gerados:**
```
../../data/images/
â”œâ”€â”€ satellite_01_Flooding_of_the_Albufera_National_Park_Post_disast.jpg
â”œâ”€â”€ satellite_02_Flooding_of_the_Albufera_National_Park_Pre_disaste.jpg
â”œâ”€â”€ satellite_03_Sentinel_1_RedCyan_composites_near_Hambatota_in_Sr.jpg
â”œâ”€â”€ satellite_04_Sentinel_1_RedCyan_composites_near_Hambatota_in_Sr.jpg
â”œâ”€â”€ satellite_05_Flooding_Event_in_Rio_Grande_do_Sul_Brazil_Post_di.jpg
â”œâ”€â”€ satellite_06_Flooding_Event_in_Rio_Grande_do_Sul_Brazil_Pre_dis.jpg
â”œâ”€â”€ satellite_07_Flooding_Event_in_Rio_Grande_do_Sul_state_Brazil_P.jpg
â”œâ”€â”€ satellite_08_Flooding_Event_in_Rio_Grande_do_Sul_state_Brazil_P.jpg
â”œâ”€â”€ satellite_09_Flooded_areas_in_Central_Scotland_Post_disaster.jpg
â”œâ”€â”€ satellite_10_Flooded_areas_in_Central_Scotland_Pre_disaster.jpg
â”œâ”€â”€ satellite_11_Floods_along_river_Reka_Ilistaya_Post_disaster.jpg
â”œâ”€â”€ satellite_12_Floods_along_river_Reka_Ilistaya_Pre_disaster.jpg
â””â”€â”€ images_metadata.json
```

---

## ğŸ“Š DADOS COLETADOS

### **Estrutura JSON**
```json
{
  "activation_id": "955",
  "title": "Flood in Bolivia",
  "date": "2025-01-18T00:00:00",
  "timestamp": 1742515200000,
  "location": {
    "country": "Bolivia",
    "region": "south america",
    "latitude": -22.277708727860684,
    "longitude": -62.614670721505604
  },
  "metadata": {
    "slug": "flood-in-bolivia-activation-955-",
    "article_id": "31235618",
    "external_reference": "ACT-1091",
    "keywords": "floods, bolivia, 2025, activation",
    "disaster_types": ["floods"]
  },
  "disaster_type": "flood",
  "severity": "medium",
  "data_source": "disasterscharter.org",
  "collected_at": "2025-06-17T01:36:00"
}
```

### **Campos Principais**
- **activation_id**: ID Ãºnico do evento
- **title**: TÃ­tulo descritivo
- **date**: Data do evento (ISO format)
- **location**: PaÃ­s, regiÃ£o e coordenadas
- **metadata**: Dados tÃ©cnicos adicionais
- **severity**: Estimativa de severidade (low/medium/high)

---

## ğŸ“ ARQUIVOS GERADOS

### **LocalizaÃ§Ã£o**
```
../../data/raw/flood_events_raw.json      # Dados brutos
../../data/processed/flood_events.json    # Dados processados + metadados
```

### **Dados Processados**
```json
{
  "metadata": {
    "total_events": 15,
    "collection_date": "2025-06-17T01:36:00",
    "source": "disasterscharter.org",
    "regions_covered": ["south america", "africa", "asia"],
    "date_range": {
      "earliest": "2024-01-15T00:00:00",
      "latest": "2025-01-18T00:00:00"
    }
  },
  "events": [...]
}
```

---

## ğŸ”§ CONFIGURAÃ‡Ã•ES

### **ParÃ¢metros AjustÃ¡veis**
```python
class DisastersCharterScraper:
    def __init__(self):
        self.delay_between_requests = 2  # Segundos entre requests
        self.max_retries = 3            # Tentativas em caso de erro
```

### **Headers HTTP**
O script usa headers que simulam um browser real para evitar bloqueios:
- User-Agent: Chrome/136.0.0.0
- Accept-Language: pt-BR,pt;q=0.9,en-US;q=0.8
- Referer: https://disasterscharter.org/activations

---

## ğŸ“ˆ EXEMPLO DE EXECUÃ‡ÃƒO

```
INFO:__main__:Iniciando coleta de dados de enchentes...
INFO:__main__:Buscando enchentes em: south america
INFO:__main__:ExtraÃ­das 3 ativaÃ§Ãµes
INFO:__main__:Coletadas 3 ativaÃ§Ãµes de south america
INFO:__main__:Buscando enchentes em: africa
INFO:__main__:ExtraÃ­das 5 ativaÃ§Ãµes
INFO:__main__:Coletadas 5 ativaÃ§Ãµes de africa
INFO:__main__:Total de ativaÃ§Ãµes Ãºnicas coletadas: 15
INFO:__main__:Dados salvos em: ../../data/raw/flood_events_raw.json
INFO:__main__:Coleta concluÃ­da! 15 eventos coletados.
INFO:__main__:PaÃ­ses com mais eventos:
INFO:__main__:  Kazakhstan: 2 eventos
INFO:__main__:  Russian Federation: 2 eventos
```

---

## ğŸŒ REGIÃ•ES COBERTAS

- **South America**: Brasil, Argentina, Peru, BolÃ­via, etc.
- **Africa**: NigÃ©ria, Congo, Ãfrica do Sul, etc.
- **Asia**: CazaquistÃ£o, China, Ãndia, etc.
- **Europe**: Alemanha, FranÃ§a, ItÃ¡lia, etc.
- **North America**: EUA, CanadÃ¡, MÃ©xico, etc.

---

## âš ï¸ CONSIDERAÃ‡Ã•ES TÃ‰CNICAS

### **Rate Limiting**
- Delay de 2 segundos entre requests
- MÃ¡ximo 3 tentativas por regiÃ£o
- Headers que simulam browser real

### **Tratamento de Erros**
- Timeout de 30 segundos por request
- Logs detalhados de erros
- ContinuaÃ§Ã£o mesmo com falhas parciais

### **Qualidade dos Dados**
- ValidaÃ§Ã£o de campos obrigatÃ³rios
- RemoÃ§Ã£o automÃ¡tica de duplicatas
- ConversÃ£o de timestamps para ISO format
- Estimativa de severidade baseada no tÃ­tulo

---

## ğŸ” DEBUGGING

### **Logs Detalhados**
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

### **Verificar Dados**
```bash
# Verificar arquivos gerados
ls -la ../../data/raw/
ls -la ../../data/processed/

# Visualizar dados coletados
python3 -c "import json; print(json.dumps(json.load(open('../../data/processed/flood_events.json')), indent=2)[:500])"
```

---

## ğŸ¯ INTEGRAÃ‡ÃƒO COM O PROJETO

Este scraper Ã© parte do sistema completo:

1. **Data Scraper** â† VocÃª estÃ¡ aqui
2. **Data Processor** â†’ Limpa e prepara dados
3. **ML Training** â†’ Treina rede neural LSTM
4. **FastAPI** â†’ Serve prediÃ§Ãµes
5. **ESP32** â†’ Coleta dados de sensores
6. **AWS Integration** â†’ Processa em tempo real

---

## ğŸ“ NOTAS IMPORTANTES

- âœ… **Dados Reais**: Fonte oficial DisastersCharter.org
- âœ… **Conformidade**: Respeita termos de uso do site
- âœ… **Atualizado**: Baseado na API atual (2025)
- âœ… **Testado**: Funcional em macOS/Linux/Windows

---

*Script desenvolvido para Global Solution 2025 - FIAP*
