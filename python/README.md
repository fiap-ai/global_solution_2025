# Python - Sistema de Monitoramento de Enchentes
## Global Solution 2025

---

## üìÅ ESTRUTURA DO PROJETO

```
python/
‚îú‚îÄ‚îÄ README.md                    # Este arquivo
‚îú‚îÄ‚îÄ data_scraper/               # Coleta autom√°tica de dados
‚îÇ   ‚îú‚îÄ‚îÄ disasters_scraper.py    # Script principal de scraping
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt        # Depend√™ncias do scraper
‚îú‚îÄ‚îÄ flood_prediction/           # Rede Neural e ML (a ser criado)
‚îú‚îÄ‚îÄ api/                       # FastAPI endpoints (a ser criado)
‚îî‚îÄ‚îÄ data_collector/            # Processamento de dados (a ser criado)
```

---

## üîß DATA SCRAPER

### **Descri√ß√£o**
Script automatizado para coleta de dados de enchentes do site oficial DisastersCharter.org usando sua API interna.

### **Funcionalidades**
- ‚úÖ Coleta autom√°tica de eventos de enchentes
- ‚úÖ Busca por m√∫ltiplas regi√µes geogr√°ficas
- ‚úÖ Extra√ß√£o de dados estruturados (JSON)
- ‚úÖ Remo√ß√£o de duplicatas
- ‚úÖ Logs detalhados de execu√ß√£o
- ‚úÖ Rate limiting respeitoso
- ‚úÖ Tratamento de erros robusto

### **Como Usar**

#### **1. Instala√ß√£o**
```bash
cd python/data_scraper
pip install -r requirements.txt
```

#### **2. Execu√ß√£o**
```bash
# Executar coleta completa
python disasters_scraper.py

# Ou importar como m√≥dulo
python -c "from disasters_scraper import DisastersCharterScraper; scraper = DisastersCharterScraper(); data = scraper.get_flood_activations(); print(f'Coletados {len(data)} eventos')"
```

### **Dados Coletados**

#### **Estrutura JSON de Sa√≠da**
```json
{
  "activation_id": "955",
  "title": "Flood in Bolivia", 
  "date": "2025-01-18T00:00:00",
  "timestamp": 1742515200000,
  "location": {
    "country": "Bolivia",
    "region": "south america", 
    "latitude": -22.277708727860684,
    "longitude": -62.614670721505604
  },
  "metadata": {
    "slug": "flood-in-bolivia-activation-955-",
    "article_id": "31235618",
    "external_reference": "ACT-1091",
    "keywords": "floods, bolivia, 2025, activation",
    "disaster_types": ["floods"]
  },
  "disaster_type": "flood",
  "severity": "medium",
  "data_source": "disasterscharter.org",
  "collected_at": "2025-06-17T01:27:00"
}
```

#### **Arquivos Gerados**
- `../../data/raw/flood_events_raw.json` - Dados brutos coletados
- `../../data/processed/flood_events.json` - Dados processados com metadados

### **Configura√ß√µes**

#### **Regi√µes Cobertas**
- South America
- Africa  
- Asia
- Europe
- North America

#### **Par√¢metros Ajust√°veis**
```python
# No c√≥digo disasters_scraper.py
self.delay_between_requests = 2  # Segundos entre requests
self.max_retries = 3            # Tentativas em caso de erro
```

### **Logs de Exemplo**
```
INFO:__main__:Iniciando coleta de dados de enchentes...
INFO:__main__:Buscando enchentes em: south america
INFO:__main__:Extra√≠das 3 ativa√ß√µes
INFO:__main__:Coletadas 3 ativa√ß√µes de south america
INFO:__main__:Total de ativa√ß√µes √∫nicas coletadas: 15
INFO:__main__:Dados salvos em: ../../data/raw/flood_events_raw.json
INFO:__main__:Coleta conclu√≠da! 15 eventos coletados.
INFO:__main__:Pa√≠ses com mais eventos:
INFO:__main__:  Bolivia: 3 eventos
INFO:__main__:  Argentina: 2 eventos
```

---

## üß† FLOOD PREDICTION (A SER IMPLEMENTADO)

### **Planejado**
- Rede Neural LSTM para predi√ß√£o de enchentes
- Processamento de s√©ries temporais
- Treinamento com dados coletados
- Modelo salvo em formato .h5

---

## üöÄ API (A SER IMPLEMENTADO)

### **Planejado**
- FastAPI para endpoints de predi√ß√£o
- Endpoint `/predict` para an√°lise em tempo real
- Endpoint `/health` para status
- Documenta√ß√£o autom√°tica em `/docs`

---

## üìä DATA COLLECTOR (A SER IMPLEMENTADO)

### **Planejado**
- Processamento de dados coletados
- Normaliza√ß√£o e limpeza
- Prepara√ß√£o para Machine Learning
- Integra√ß√£o com APIs clim√°ticas

---

## üîÑ WORKFLOW COMPLETO

### **1. Coleta de Dados**
```bash
cd python/data_scraper
python disasters_scraper.py
```

### **2. Processamento (Futuro)**
```bash
cd python/data_collector  
python process_data.py
```

### **3. Treinamento ML (Futuro)**
```bash
cd python/flood_prediction
python train_model.py
```

### **4. API Local (Futuro)**
```bash
cd python/api
uvicorn main:app --reload
```

---

## üìã DEPEND√äNCIAS

### **Data Scraper**
- `requests>=2.25.0` - HTTP requests

### **Futuras Depend√™ncias**
- `tensorflow>=2.10.0` - Rede Neural
- `fastapi>=0.68.0` - API endpoints
- `pandas>=1.3.0` - Manipula√ß√£o de dados
- `numpy>=1.21.0` - Computa√ß√£o num√©rica
- `scikit-learn>=1.0.0` - ML utilities

---

## ‚ö†Ô∏è CONSIDERA√á√ïES IMPORTANTES

### **Rate Limiting**
- Delay de 2 segundos entre requests
- Headers que simulam browser real
- Respeito aos termos de uso do site

### **Dados Reais**
- ‚úÖ Fonte oficial: DisastersCharter.org
- ‚úÖ Dados estruturados e validados
- ‚úÖ Coordenadas geogr√°ficas precisas
- ‚úÖ Timestamps e metadados completos

### **Qualidade dos Dados**
- Remo√ß√£o autom√°tica de duplicatas
- Valida√ß√£o de campos obrigat√≥rios
- Logs detalhados para debugging
- Tratamento de erros robusto

---

## üéØ PR√ìXIMOS PASSOS

1. **Executar data_scraper** para coletar dados iniciais
2. **Implementar flood_prediction** com LSTM
3. **Criar API FastAPI** para predi√ß√µes
4. **Integrar com ESP32** via AWS
5. **Documentar resultados** no PDF final

---

*Este m√≥dulo Python √© parte integral do sistema de monitoramento de enchentes para a Global Solution 2025.*
